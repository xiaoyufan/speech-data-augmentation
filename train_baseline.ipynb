{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (0.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/blake/anaconda3/envs/deepspeech-train/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/blake/anaconda3/envs/deepspeech-train/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATASET_PATH = os.getenv('DATASET_PATH')\n",
    "DEEPSPEECH_LOG_LEVEL = os.getenv('DEEPSPEECH_LOG_LEVEL')\n",
    "DEEPSPEECH_PATH = os.getenv('DEEPSPEECH_PATH')\n",
    "LOGGING_LEVEL = os.getenv('LOGGING_LEVEL')\n",
    "USE_GPU = bool(os.getenv('USE_GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-08 13:35:07,850 - logger baseline - DEBUG] debug test\n",
      "[2020-12-08 13:35:07,852 - logger baseline - INFO] info test\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "reload(logging)\n",
    "\n",
    "logger = logging.getLogger('baseline')\n",
    "logger.setLevel(LOGGING_LEVEL)\n",
    "\n",
    "formatter = logging.Formatter('[%(asctime)s - logger %(name)s - %(levelname)s] %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.debug('debug test')\n",
    "logger.info('info test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-08 13:35:09,144 - logger baseline - INFO] tensorflow version: 1.15.4\n",
      "[2020-12-08 13:35:09,152 - logger baseline - INFO] Not using GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "logger.info(f'tensorflow version: {tf.__version__}')\n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    logger.info('Using Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   logger.info(\"Not using GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform tensorflow-challenge dataset into DeepSpeech format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES_PATH = f'{DATASET_PATH}/train/training_files.csv'\n",
    "TEST_FILES_PATH = f'{DATASET_PATH}/test/testing_files.csv'\n",
    "\n",
    "# For now, we don't use test/audio because its audio files don't have transcriptions.\n",
    "# Instead, we split train/audio into training set and testing set.\n",
    "WAV_TRAIN_DIR = f'{DATASET_PATH}/train/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-08 13:35:09,192 - logger baseline - INFO] Skipping transforming data. Data files /mnt/c/Users/tohru/Desktop/Accented Speech Recognition/Project - Accented Speech Recognition/Dataset/tensorflow-speech-recognition-challenge/train/training_files.csv and /mnt/c/Users/tohru/Desktop/Accented Speech Recognition/Project - Accented Speech Recognition/Dataset/tensorflow-speech-recognition-challenge/test/testing_files.csv already exist. \n"
     ]
    }
   ],
   "source": [
    "# Importer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_testing_files():\n",
    "    testing_list_path = f'{DATASET_PATH}/train/testing_list.txt'\n",
    "\n",
    "    with open(testing_list_path) as file:\n",
    "        testing_files = [line.rstrip() for line in file]\n",
    "        return testing_files\n",
    "\n",
    "\n",
    "def generate_files_list(testing_files):\n",
    "    if (os.path.exists(TRAIN_FILES_PATH) and\n",
    "            os.path.exists(TEST_FILES_PATH)):\n",
    "        logger.info(f'Skipping transforming data. Data files {TRAIN_FILES_PATH} and {TEST_FILES_PATH} already exist. ')\n",
    "        return\n",
    "\n",
    "    COLUMNS = ['wav_filename', 'wav_filesize', 'transcript']\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "\n",
    "    for path in Path(WAV_TRAIN_DIR).rglob('*.wav'):\n",
    "        wav_path_relative_to_wav_dir = str(path.relative_to(WAV_TRAIN_DIR))\n",
    "        wav_set = None\n",
    "\n",
    "        if wav_path_relative_to_wav_dir in testing_files:\n",
    "            wav_set = 'testing'\n",
    "        else:\n",
    "            wav_set = 'training'\n",
    "\n",
    "        wav_filename = path.name\n",
    "        transcript = wav_path_relative_to_wav_dir.split('/')[0]\n",
    "\n",
    "        logger.debug(\n",
    "            f'Wav: {wav_path_relative_to_wav_dir}; Dataset: {wav_set}; Transcript: {transcript}')\n",
    "\n",
    "        data = (str(path),\n",
    "                path.stat().st_size,\n",
    "                transcript)\n",
    "\n",
    "        if wav_set == 'training':\n",
    "            if transcript == '_background_noise_':\n",
    "                logger.debug(f'SKipping adding {wav_filename} to files list.')\n",
    "                continue\n",
    "\n",
    "            training_data.append(data)\n",
    "            \n",
    "        if wav_set == 'testing':\n",
    "            testing_data.append(data)\n",
    "\n",
    "    training_df = pandas.DataFrame(\n",
    "        data=training_data,\n",
    "        columns=COLUMNS,\n",
    "    )\n",
    "    training_df.to_csv(os.path.join(TRAIN_FILES_PATH), index=False)\n",
    "    logger.info(f'Train data files generated at {TRAIN_FILES_PATH}.')\n",
    "\n",
    "    testing_df = pandas.DataFrame(\n",
    "        data=testing_data,\n",
    "        columns=COLUMNS,\n",
    "    )\n",
    "    testing_df.to_csv(os.path.join(TEST_FILES_PATH), index=False)\n",
    "    logger.info(f'Test data files generated at {TRAIN_FILES_PATH}.')\n",
    "\n",
    "\n",
    "def transform_data():\n",
    "    # Load testing files list\n",
    "    testing_files = load_testing_files()\n",
    "    # Generate files list\n",
    "    generate_files_list(testing_files)\n",
    "\n",
    "\n",
    "transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 13:35:10.784901: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-12-08 13:35:10.789517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592005000 Hz\n",
      "2020-12-08 13:35:10.790930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b8efcda470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-08 13:35:10.790972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W1208 13:35:12.203429 140435406763840 deprecation.py:323] From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W1208 13:35:12.203747 140435406763840 deprecation.py:323] From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "W1208 13:35:12.203885 140435406763840 deprecation.py:323] From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1208 13:35:12.291809 140435406763840 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "W1208 13:35:12.294272 140435406763840 deprecation.py:323] From /home/blake/anaconda3/envs/deepspeech-train/lib/python3.6/site-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /mnt/c/Users/tohru/Workspace/NEU/DeepSpeech/training/deepspeech_training/train.py:249: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1208 13:35:12.411803 140435406763840 deprecation.py:323] From /mnt/c/Users/tohru/Workspace/NEU/DeepSpeech/training/deepspeech_training/train.py:249: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "D Session opened.\n",
      "I Could not find best validating checkpoint.\n",
      "I Loading most recent checkpoint from /home/blake/.local/share/deepspeech/checkpoints/train-469\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "WARNING:tensorflow:From /mnt/c/Users/tohru/Workspace/NEU/DeepSpeech/training/deepspeech_training/util/checkpoints.py:71: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "W1208 13:35:12.910267 140435406763840 deprecation.py:323] From /mnt/c/Users/tohru/Workspace/NEU/DeepSpeech/training/deepspeech_training/util/checkpoints.py:71: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/bias/Adam\n",
      "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Loading variable from checkpoint: layer_6/weights/Adam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 256 | Loss: 12.348753    "
     ]
    }
   ],
   "source": [
    "!python \"$DEEPSPEECH_PATH/DeepSpeech.py\" --alphabet_config_path=\"$DEEPSPEECH_PATH/data/alphabet.txt\" --train_files \"$TRAIN_FILES_PATH\" --test_files \"$TEST_FILES_PATH\" --log_level \"$DEEPSPEECH_LOG_LEVEL\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train-baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bFfVy0dnirFx",
        "djmMcMsMYHuY",
        "smHI6JjeirFz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoyufan/speech-data-augmentation/blob/main/train_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPOPfVuOirFV"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws9EGcGHdEQh"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/train-baseline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ-rvDakjHwE"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kx-0eCviwtB",
        "outputId": "a6afa51f-13a9-4caf-a139-2fd7b7c5d399"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqLFhsJKjQUG"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDxpGWSjPXU"
      },
      "source": [
        "DRIVE_PROJECT_ROOT_PATH = '/content/drive/MyDrive/nlp-project'\r\n",
        "DATASET_PATH = f'{DRIVE_PROJECT_ROOT_PATH}/tensorflow-speech-recognition-challenge'\r\n",
        "DEEPSPEECH_LOG_LEVEL = '0'\r\n",
        "DEEPSPEECH_PATH = '/content/DeepSpeech'\r\n",
        "LOGGING_LEVEL = 'DEBUG'\r\n",
        "USE_GPU = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx7mnMEdirFz"
      },
      "source": [
        "TRAIN_FILES_PATH = f'{DATASET_PATH}/playground/training_files.csv'\n",
        "TEST_FILES_PATH = f'{DATASET_PATH}/playground/testing_files.csv'\n",
        "\n",
        "# For now, we don't use test/audio because its audio files don't have transcriptions.\n",
        "# Instead, we split train/audio into training set and testing set.\n",
        "WAV_TRAIN_DIR = f'{DATASET_PATH}/playground/audio'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFfVy0dnirFx"
      },
      "source": [
        "## Create logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S79MdUiirFx",
        "outputId": "6b9f45d0-2bd5-43b7-aef5-fbac81282fae"
      },
      "source": [
        "from importlib import reload\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "reload(logging)\n",
        "\n",
        "logger = logging.getLogger('baseline')\n",
        "logger.setLevel(LOGGING_LEVEL)\n",
        "\n",
        "formatter = logging.Formatter('[%(asctime)s - logger %(name)s - %(levelname)s] %(message)s')\n",
        "\n",
        "ch = logging.StreamHandler(sys.stdout)\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)\n",
        "\n",
        "logger.debug('debug test')\n",
        "logger.info('info test')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-09 06:23:45,576 - logger baseline - DEBUG] debug test\n",
            "[2020-12-09 06:23:45,577 - logger baseline - INFO] info test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOfWKNhNirFs"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djmMcMsMYHuY"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLjH9JzAYKFu",
        "outputId": "1182eb62-4966-44ce-9227-f34ad49c1f6e"
      },
      "source": [
        "%%bash -s \"$DEEPSPEECH_PATH\"\r\n",
        "DEEPSPEECH_PATH=$1\r\n",
        "\r\n",
        "if [ ! -d \"$DEEPSPEECH_PATH\" ] ; then\r\n",
        "  git clone --branch v0.9.2 https://github.com/mozilla/DeepSpeech $DEEPSPEECH_PATH\r\n",
        "fi\r\n",
        "\r\n",
        "cd $DEEPSPEECH_PATH\r\n",
        "pip install --upgrade pip==20.2.2 wheel==0.34.2 setuptools==49.6.0\r\n",
        "pip install --upgrade -e .\r\n",
        "\r\n",
        "# pip uninstall tensorflow -y\r\n",
        "pip install --upgrade tensorflow==1.15.4\r\n",
        "pip install tensorflow-gpu==1.15.4\r\n",
        "\r\n",
        "# Install other packages\r\n",
        "pip install pandas\r\n",
        "# tensorflow 1.15.4 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\r\n",
        "pip install --upgrade numpy==1.16.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip==20.2.2 in /usr/local/lib/python3.6/dist-packages (20.2.2)\n",
            "Requirement already up-to-date: wheel==0.34.2 in /usr/local/lib/python3.6/dist-packages (0.34.2)\n",
            "Requirement already up-to-date: setuptools==49.6.0 in /usr/local/lib/python3.6/dist-packages (49.6.0)\n",
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (3.38.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyxdg in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.27)\n",
            "Requirement already satisfied, skipping upgrade: attrdict in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: semver in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (2.13.0)\n",
            "Requirement already satisfied, skipping upgrade: opuslib==2.0.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: optuna in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: sox in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numba==0.47.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.47.0)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite==0.31.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.31.0)\n",
            "Requirement already satisfied, skipping upgrade: librosa in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.6.3)\n",
            "Requirement already satisfied, skipping upgrade: soundfile in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.10.3.post1)\n",
            "Requirement already satisfied, skipping upgrade: ds_ctcdecoder==0.9.2 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (0.9.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow==1.15.4 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.2) (1.15.4)\n",
            "Requirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->deepspeech-training==0.9.2) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (4.6.2)\n",
            "Requirement already satisfied, skipping upgrade: cliff in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (3.5.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: alembic in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (1.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (1.3.20)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: cmaes>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.2) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->deepspeech-training==0.9.2) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.2) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.2) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.2) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.2) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.2) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.2) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.47.0->deepspeech-training==0.9.2) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.2) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.2) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.2) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.2) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->deepspeech-training==0.9.2) (1.14.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.2) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (0.7.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cmd2!=0.8.3,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: stevedore>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.2) (5.5.1)\n",
            "Requirement already satisfied, skipping upgrade: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna->deepspeech-training==0.9.2) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna->deepspeech-training==0.9.2) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.9.2) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.2) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.2) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.2) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyperclip>=1.6 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: colorama>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.9.2) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.2) (3.4.0)\n",
            "Installing collected packages: deepspeech-training\n",
            "  Attempting uninstall: deepspeech-training\n",
            "    Found existing installation: deepspeech-training 0.9.2\n",
            "    Can't uninstall 'deepspeech-training'. No files were found to uninstall.\n",
            "  Running setup.py develop for deepspeech-training\n",
            "Successfully installed deepspeech-training\n",
            "Requirement already up-to-date: tensorflow==1.15.4 in /usr/local/lib/python3.6/dist-packages (1.15.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.4) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.4.0)\n",
            "Requirement already satisfied: tensorflow-gpu==1.15.4 in /usr/local/lib/python3.6/dist-packages (1.15.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.33.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.4) (49.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already up-to-date: numpy==1.16.0 in /usr/local/lib/python3.6/dist-packages (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFss5P5irFy"
      },
      "source": [
        "### Verify tensorflow can run on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmcWuwOTirFy",
        "outputId": "6c110c7e-acd2-4203-dfa6-7ad8330ae056"
      },
      "source": [
        "import tensorflow as tf\n",
        "logger.info(f'tensorflow version: {tf.__version__}')\n",
        "\n",
        "if tf.test.gpu_device_name(): \n",
        "    logger.info('Using Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   logger.info(\"Not using GPU\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-09 06:24:10,011 - logger baseline - INFO] tensorflow version: 1.15.4\n",
            "[2020-12-09 06:24:10,310 - logger baseline - INFO] Using Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smHI6JjeirFz"
      },
      "source": [
        "## Transform tensorflow-challenge dataset into DeepSpeech format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh_KFIDMirF0",
        "outputId": "a791c5e5-0563-4736-81ce-1449f85df737"
      },
      "source": [
        "# Importer\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def load_testing_files():\n",
        "    testing_list_path = f'{DATASET_PATH}/train/testing_list.txt'\n",
        "\n",
        "    with open(testing_list_path) as file:\n",
        "        testing_files = [line.rstrip() for line in file]\n",
        "        return testing_files\n",
        "\n",
        "\n",
        "def generate_files_list(testing_files):\n",
        "    if (os.path.exists(TRAIN_FILES_PATH) and\n",
        "            os.path.exists(TEST_FILES_PATH)):\n",
        "        logger.info(f'Skipping transforming data. Data files {TRAIN_FILES_PATH} and {TEST_FILES_PATH} already exist. ')\n",
        "        return\n",
        "\n",
        "    COLUMNS = ['wav_filename', 'wav_filesize', 'transcript']\n",
        "    training_data = []\n",
        "    testing_data = []\n",
        "\n",
        "    for path in Path(WAV_TRAIN_DIR).rglob('*.wav'):\n",
        "        wav_path_relative_to_wav_dir = str(path.relative_to(WAV_TRAIN_DIR))\n",
        "        wav_set = None\n",
        "\n",
        "        if wav_path_relative_to_wav_dir in testing_files:\n",
        "            wav_set = 'testing'\n",
        "        else:\n",
        "            wav_set = 'training'\n",
        "\n",
        "        wav_filename = path.name\n",
        "        transcript = wav_path_relative_to_wav_dir.split('/')[0]\n",
        "\n",
        "        logger.debug(\n",
        "            f'Wav: {wav_path_relative_to_wav_dir}; Dataset: {wav_set}; Transcript: {transcript}')\n",
        "\n",
        "        data = (str(path),\n",
        "                path.stat().st_size,\n",
        "                transcript)\n",
        "\n",
        "        if wav_set == 'training':\n",
        "            if transcript == '_background_noise_':\n",
        "                logger.debug(f'SKipping adding {wav_filename} to files list.')\n",
        "                continue\n",
        "\n",
        "            training_data.append(data)\n",
        "            \n",
        "        if wav_set == 'testing':\n",
        "            testing_data.append(data)\n",
        "\n",
        "    training_df = pandas.DataFrame(\n",
        "        data=training_data,\n",
        "        columns=COLUMNS,\n",
        "    )\n",
        "    training_df.to_csv(os.path.join(TRAIN_FILES_PATH), index=False)\n",
        "    logger.info(f'Train data files generated at {TRAIN_FILES_PATH}.')\n",
        "\n",
        "    testing_df = pandas.DataFrame(\n",
        "        data=testing_data,\n",
        "        columns=COLUMNS,\n",
        "    )\n",
        "    testing_df.to_csv(os.path.join(TEST_FILES_PATH), index=False)\n",
        "    logger.info(f'Test data files generated at {TRAIN_FILES_PATH}.')\n",
        "\n",
        "\n",
        "def transform_data():\n",
        "    # Load testing files list\n",
        "    testing_files = load_testing_files()\n",
        "    # Generate files list\n",
        "    generate_files_list(testing_files)\n",
        "\n",
        "\n",
        "transform_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-12-09 06:24:10,387 - logger baseline - INFO] Skipping transforming data. Data files /content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/training_files.csv and /content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/testing_files.csv already exist. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cajWfK1vkrX"
      },
      "source": [
        "## Train a baseline model\r\n",
        "\r\n",
        "Train a DeepSpeech model with Kaggle Tensorflow challenge's dataset to establish the baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65cHU_DoirF0",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7983e3f7-e12c-4532-a558-143d9a705d4a"
      },
      "source": [
        "%%bash -s \"$DEEPSPEECH_PATH\" \"$TRAIN_FILES_PATH\" \"$TEST_FILES_PATH\" \"$DRIVE_PROJECT_ROOT_PATH\" \"$DEEPSPEECH_LOG_LEVEL\"\r\n",
        "DEEPSPEECH_PATH=$1\r\n",
        "TRAIN_FILES_PATH=$2\r\n",
        "TEST_FILES_PATH=$3\r\n",
        "DRIVE_PROJECT_ROOT_PATH=$4\r\n",
        "DEEPSPEECH_LOG_LEVEL=$5\r\n",
        "\r\n",
        "cd $DEEPSPEECH_PATH\r\n",
        "python DeepSpeech.py \\\r\n",
        "  --alphabet_config_path=data/alphabet.txt \\\r\n",
        "  --train_files \"$TRAIN_FILES_PATH\" \\\r\n",
        "  --test_files \"$TEST_FILES_PATH\" \\\r\n",
        "  --checkpoint_dir \"$DRIVE_PROJECT_ROOT_PATH/xiaoyu-baseline/checkpoints\" \\\r\n",
        "  --export_dir \"$DRIVE_PROJECT_ROOT_PATH/xiaoyu-baseline/models\" \\\r\n",
        "  --log_level \"$DEEPSPEECH_LOG_LEVEL\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D Session opened.\n",
            "I Could not find best validating checkpoint.\n",
            "I Loading most recent checkpoint from /content/drive/MyDrive/nlp-project/xiaoyu-baseline/checkpoints/train-53\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I STARTING Optimization\n",
            "\r                                                                               \r\rEpoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.687317       \r                                                                               \r\rEpoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.687317       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.551021       \r                                                                               \r\rEpoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.551021       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.328133       \r                                                                               \r\rEpoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.328133       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 3 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 3 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.213634       \r                                                                               \r\rEpoch 3 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.213634       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 4 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 4 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.511512       \r                                                                               \r\rEpoch 4 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.511512       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 5 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 5 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.384306       \r                                                                               \r\rEpoch 5 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.384306       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 6 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 6 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.176445       \r                                                                               \r\rEpoch 6 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.176445       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 7 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 7 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.264112       \r                                                                               \r\rEpoch 7 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.264112       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 8 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 8 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.306361       \r                                                                               \r\rEpoch 8 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.306361       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 9 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       \r                                                                               \r\rEpoch 9 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.250942       \r                                                                               \r\rEpoch 9 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.250942       \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 10 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 10 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.362009      \r                                                                               \r\rEpoch 10 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.362009      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 11 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 11 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.340951      \r                                                                               \r\rEpoch 11 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.340951      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 12 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 12 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141141      \r                                                                               \r\rEpoch 12 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141141      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 13 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 13 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.062383      \r                                                                               \r\rEpoch 13 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.062383      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 14 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 14 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.143970      \r                                                                               \r\rEpoch 14 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.143970      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 15 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 15 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.211648      \r                                                                               \r\rEpoch 15 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.211648      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 16 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 16 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.192796      \r                                                                               \r\rEpoch 16 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.192796      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 17 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 17 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.073935      \r                                                                               \r\rEpoch 17 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.073935      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 18 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 18 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141719      \r                                                                               \r\rEpoch 18 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141719      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 19 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 19 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.109079      \r                                                                               \r\rEpoch 19 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.109079      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 20 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 20 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.127993      \r                                                                               \r\rEpoch 20 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.127993      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 21 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 21 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.135479      \r                                                                               \r\rEpoch 21 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.135479      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 22 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 22 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.978404      \r                                                                               \r\rEpoch 22 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.978404      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 23 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 23 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.146550      \r                                                                               \r\rEpoch 23 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.146550      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 24 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 24 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.110031      \r                                                                               \r\rEpoch 24 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.110031      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 25 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 25 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.065345      \r                                                                               \r\rEpoch 25 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.065345      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 26 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 26 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.012430      \r                                                                               \r\rEpoch 26 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.012430      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 27 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 27 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.019608      \r                                                                               \r\rEpoch 27 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.019608      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 28 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 28 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.073150      \r                                                                               \r\rEpoch 28 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.073150      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 29 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 29 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.000113      \r                                                                               \r\rEpoch 29 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.000113      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 30 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 30 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.201412      \r                                                                               \r\rEpoch 30 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.201412      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 31 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 31 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.167024      \r                                                                               \r\rEpoch 31 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.167024      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 32 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 32 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.047528      \r                                                                               \r\rEpoch 32 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.047528      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 33 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 33 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.038730      \r                                                                               \r\rEpoch 33 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.038730      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 34 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 34 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.051929      \r                                                                               \r\rEpoch 34 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.051929      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 35 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 35 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.140460      \r                                                                               \r\rEpoch 35 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.140460      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 36 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 36 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.220207      \r                                                                               \r\rEpoch 36 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 8.220207      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 37 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 37 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.145625      \r                                                                               \r\rEpoch 37 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.145625      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 38 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 38 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.998525      \r                                                                               \r\rEpoch 38 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.998525      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 39 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 39 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.102757      \r                                                                               \r\rEpoch 39 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.102757      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 40 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 40 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.224118      \r                                                                               \r\rEpoch 40 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.224118      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 41 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 41 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.085397      \r                                                                               \r\rEpoch 41 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.085397      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 42 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 42 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.196658      \r                                                                               \r\rEpoch 42 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.196658      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 43 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 43 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.183159      \r                                                                               \r\rEpoch 43 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.183159      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 44 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 44 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141459      \r                                                                               \r\rEpoch 44 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.141459      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 45 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 45 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.267264      \r                                                                               \r\rEpoch 45 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.267264      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 46 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 46 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.092233      \r                                                                               \r\rEpoch 46 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.092233      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 47 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 47 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.249388      \r                                                                               \r\rEpoch 47 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.249388      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 48 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 48 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.139517      \r                                                                               \r\rEpoch 48 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.139517      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 49 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 49 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.072735      \r                                                                               \r\rEpoch 49 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.072735      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 50 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 50 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.077621      \r                                                                               \r\rEpoch 50 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.077621      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 51 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 51 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.048517      \r                                                                               \r\rEpoch 51 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.048517      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 52 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 52 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.186830      \r                                                                               \r\rEpoch 52 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.186830      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 53 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 53 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.088896      \r                                                                               \r\rEpoch 53 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.088896      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 54 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 54 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.119100      \r                                                                               \r\rEpoch 54 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.119100      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 55 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 55 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.018397      \r                                                                               \r\rEpoch 55 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.018397      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 56 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 56 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.055152      \r                                                                               \r\rEpoch 56 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.055152      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 57 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 57 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.160563      \r                                                                               \r\rEpoch 57 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.160563      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 58 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 58 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.019361      \r                                                                               \r\rEpoch 58 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.019361      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 59 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 59 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.158044      \r                                                                               \r\rEpoch 59 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.158044      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 60 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 60 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.099186      \r                                                                               \r\rEpoch 60 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.099186      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 61 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 61 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.114238      \r                                                                               \r\rEpoch 61 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.114238      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 62 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 62 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.198972      \r                                                                               \r\rEpoch 62 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.198972      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 63 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 63 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.097485      \r                                                                               \r\rEpoch 63 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.097485      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 64 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 64 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.133407      \r                                                                               \r\rEpoch 64 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.133407      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 65 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 65 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.037932      \r                                                                               \r\rEpoch 65 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.037932      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 66 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 66 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.274430      \r                                                                               \r\rEpoch 66 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.274430      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 67 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 67 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.003753      \r                                                                               \r\rEpoch 67 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.003753      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 68 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 68 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.016089      \r                                                                               \r\rEpoch 68 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.016089      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 69 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 69 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.049562      \r                                                                               \r\rEpoch 69 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.049562      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 70 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 70 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.965931      \r                                                                               \r\rEpoch 70 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.965931      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 71 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 71 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.210782      \r                                                                               \r\rEpoch 71 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.210782      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 72 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 72 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.038462      \r                                                                               \r\rEpoch 72 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.038462      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 73 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 73 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.026484      \r                                                                               \r\rEpoch 73 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.026484      \n",
            "--------------------------------------------------------------------------------\n",
            "\r                                                                               \r\rEpoch 74 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000      \r                                                                               \r\rEpoch 74 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.184957      \r                                                                               \r\rEpoch 74 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 8.184957      \n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:08:46.306158\n",
            "D Session closed.\n",
            "I Could not find best validating checkpoint.\n",
            "I Loading most recent checkpoint from /content/drive/MyDrive/nlp-project/xiaoyu-baseline/checkpoints/train-128\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/testing_files.csv\n",
            "\r                                                                               \r\rTest epoch | Steps: 0 | Elapsed Time: 0:00:00                                  \r                                                                               \r\rTest epoch | Steps: 1 | Elapsed Time: 0:00:00                                  \r                                                                               \r\rTest epoch | Steps: 1 | Elapsed Time: 0:00:00                                  \n",
            "Test on /content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/testing_files.csv - WER: 1.000000, CER: 0.800000, loss: 8.165524\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.800000, loss: 8.165524\n",
            " - wav: file:///content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/audio/bed/0b09edd3_nohash_0.wav\n",
            " - src: \"seven\"\n",
            " - res: \"e\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.800000, loss: 8.165524\n",
            " - wav: file:///content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/audio/bed/0b09edd3_nohash_0.wav\n",
            " - src: \"seven\"\n",
            " - res: \"e\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.800000, loss: 8.165524\n",
            " - wav: file:///content/drive/MyDrive/nlp-project/tensorflow-speech-recognition-challenge/playground/audio/bed/0b09edd3_nohash_0.wav\n",
            " - src: \"seven\"\n",
            " - res: \"e\"\n",
            "--------------------------------------------------------------------------------\n",
            "I Exporting the model...\n",
            "I Could not find best validating checkpoint.\n",
            "I Loading most recent checkpoint from /content/drive/MyDrive/nlp-project/xiaoyu-baseline/checkpoints/train-128\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Models exported at /content/drive/MyDrive/nlp-project/xiaoyu-baseline/models\n",
            "I Model metadata file saved to /content/drive/MyDrive/nlp-project/xiaoyu-baseline/models/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-09 06:24:12.587361: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-09 06:24:12.594705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-09 06:24:12.595067: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x235af40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-09 06:24:12.595091: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-09 06:24:12.597235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-09 06:24:12.710393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.711095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x235b100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-09 06:24:12.711128: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-12-09 06:24:12.711325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.711904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-09 06:24:12.712299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:24:12.713518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:24:12.714699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-09 06:24:12.715108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-09 06:24:12.716408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-09 06:24:12.717386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-09 06:24:12.723720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-09 06:24:12.724067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.725143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.726107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-12-09 06:24:12.726344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:24:12.728433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-09 06:24:12.728536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-12-09 06:24:12.728721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-12-09 06:24:12.729148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.730335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:12.731246: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-09 06:24:12.731354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "I1209 06:24:13.520007 140630258493312 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "2020-12-09 06:24:14.404371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:14.405009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-09 06:24:14.405092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:24:14.405120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:24:14.405142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-09 06:24:14.405162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-09 06:24:14.405183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-09 06:24:14.405211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-09 06:24:14.405234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-09 06:24:14.405330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:14.405901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:14.406460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "W1209 06:24:14.800780 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "W1209 06:24:14.801102 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "W1209 06:24:14.801276 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1209 06:24:14.900799 140630258493312 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W1209 06:24:14.902863 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /content/DeepSpeech/training/deepspeech_training/train.py:249: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1209 06:24:14.972760 140630258493312 deprecation.py:323] From /content/DeepSpeech/training/deepspeech_training/train.py:249: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2020-12-09 06:24:15.607821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:15.608464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-09 06:24:15.608542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:24:15.608566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:24:15.608581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-09 06:24:15.608599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-09 06:24:15.608617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-09 06:24:15.608635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-09 06:24:15.608653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-09 06:24:15.608729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:15.609302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:15.609785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-12-09 06:24:15.609825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-09 06:24:15.609839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-12-09 06:24:15.609848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-12-09 06:24:15.609959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:15.610502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:24:15.611015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/DeepSpeech/training/deepspeech_training/util/checkpoints.py:71: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W1209 06:24:15.623767 140630258493312 deprecation.py:323] From /content/DeepSpeech/training/deepspeech_training/util/checkpoints.py:71: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2020-12-09 06:24:20.640757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:24:21.006310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1209 06:24:58.280885 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2020-12-09 06:33:07.195156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:07.205287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-09 06:33:07.266951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:33:07.273845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:33:07.277599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-09 06:33:07.281987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-09 06:33:07.285593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-09 06:33:07.289530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-09 06:33:07.296419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-09 06:33:07.296618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:07.297567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:07.298292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-12-09 06:33:07.304606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-09 06:33:07.304642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-12-09 06:33:07.309071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-12-09 06:33:07.312223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:07.313005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:07.314280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/DeepSpeech/training/deepspeech_training/train.py:708: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "W1209 06:33:09.503373 140630258493312 module_wrapper.py:139] From /content/DeepSpeech/training/deepspeech_training/train.py:708: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DeepSpeech/training/deepspeech_training/train.py:807: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1209 06:33:09.748455 140630258493312 module_wrapper.py:139] From /content/DeepSpeech/training/deepspeech_training/train.py:807: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-09 06:33:09.757581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:09.758322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-09 06:33:09.758411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-09 06:33:09.758439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-09 06:33:09.758481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-09 06:33:09.758501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-09 06:33:09.758518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-09 06:33:09.758538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-09 06:33:09.758557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-09 06:33:09.758658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:09.759445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:09.760324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-12-09 06:33:09.760432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-09 06:33:09.760455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-12-09 06:33:09.760465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-12-09 06:33:09.760613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:09.761391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-09 06:33:09.762087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/DeepSpeech/training/deepspeech_training/train.py:825: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1209 06:33:10.513213 140630258493312 deprecation.py:323] From /content/DeepSpeech/training/deepspeech_training/train.py:825: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1209 06:33:10.513482 140630258493312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 12 variables.\n",
            "I1209 06:33:10.569060 140630258493312 graph_util_impl.py:334] Froze 12 variables.\n",
            "INFO:tensorflow:Converted 12 variables to const ops.\n",
            "I1209 06:33:10.977293 140630258493312 graph_util_impl.py:394] Converted 12 variables to const ops.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}